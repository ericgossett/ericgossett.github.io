{"componentChunkName":"component---src-templates-project-page-js","path":"/tf-boilerplate","webpackCompilationHash":"d065b9e2a60d417d4855","result":{"data":{"markdownRemark":{"html":"<p>I found that it is not to hard for Tensorflow projects to become monoliths if one does not take some consideration when organizing their code. As a result, I decided to search look for some guidelines on how to structure a Tensorflow project and came across this popular template <a href=\"https://github.com/MrGemy95/Tensorflow-Project-Template\">link</a>. Looking through the code, I found a lot to love, however, like any boilerplate I also found some things I did not like. This inspired me to write my own boilerplate, taking insipiration from what I liked in this project, while giving it my own flare.</p>\n<p><strong>Repo:</strong> <a href=\"https://github.com/ericgossett/tf-boilerplate\">https://github.com/ericgossett/tf-boilerplate</a></p>\n<h2>Structure</h2>\n<div class=\"gatsby-highlight\" data-language=\"bash\"><pre class=\"language-bash\"><code class=\"language-bash\">core/\n    exceptions.py\n    logger.py\n    model.py\n    trainer.py\n    validators.py\nlogs/\nsnapshots/\nmain.py</code></pre></div>\n<ul>\n<li><strong>core</strong> - contains the main functionality of the boilerplate.</li>\n<li><strong>logs</strong> - Where session logs are stored for tensorboard visualization.</li>\n<li><strong>snapshots</strong> - Where models are saved.</li>\n</ul>\n<h2>Core</h2>\n<p>As seen in the template this is based off of I also decided to use the same architecture consisting of a model, trainer and logger component. </p>\n<h3>Model</h3>\n<p>The model component is an abstract class containing the following: </p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">class</span> <span class=\"token class-name\">Model</span><span class=\"token punctuation\">:</span>\n    <span class=\"token triple-quoted-string string\">\"\"\"Base class for a Tensorflow models\n    Args:\n        config (dict): The configuration.\n    \"\"\"</span>\n    <span class=\"token keyword\">def</span> <span class=\"token function\">__init__</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> config<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        config_validator<span class=\"token punctuation\">(</span>config<span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>config <span class=\"token operator\">=</span> config\n        self<span class=\"token punctuation\">.</span>name <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>config<span class=\"token punctuation\">[</span><span class=\"token string\">'name'</span><span class=\"token punctuation\">]</span>\n        self<span class=\"token punctuation\">.</span>saver <span class=\"token operator\">=</span> <span class=\"token boolean\">None</span>\n        <span class=\"token keyword\">with</span> tf<span class=\"token punctuation\">.</span>variable_scope<span class=\"token punctuation\">(</span><span class=\"token string\">'global_step'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n            self<span class=\"token punctuation\">.</span>global_step <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>Variable<span class=\"token punctuation\">(</span>\n                <span class=\"token number\">0</span><span class=\"token punctuation\">,</span>\n                trainable<span class=\"token operator\">=</span><span class=\"token boolean\">False</span><span class=\"token punctuation\">,</span>\n                name<span class=\"token operator\">=</span><span class=\"token string\">'global_step'</span>\n            <span class=\"token punctuation\">)</span>\n\n        self<span class=\"token punctuation\">.</span>x <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>placeholder<span class=\"token punctuation\">(</span>tf<span class=\"token punctuation\">.</span>float32<span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>y <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>placeholder<span class=\"token punctuation\">(</span>tf<span class=\"token punctuation\">.</span>float32<span class=\"token punctuation\">)</span>\n\n        self<span class=\"token punctuation\">.</span>data <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>data<span class=\"token punctuation\">.</span>Dataset<span class=\"token punctuation\">.</span>from_tensor_slices<span class=\"token punctuation\">(</span>\n            <span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span>x<span class=\"token punctuation\">,</span> self<span class=\"token punctuation\">.</span>y<span class=\"token punctuation\">)</span>\n        <span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>batch<span class=\"token punctuation\">(</span>\n            config<span class=\"token punctuation\">[</span><span class=\"token string\">'batch_size'</span><span class=\"token punctuation\">]</span>\n        <span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>repeat<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>data_iter <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>data<span class=\"token punctuation\">.</span>make_initializable_iterator<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">model_constructor</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token triple-quoted-string string\">\"\"\"Abstract method used to define the model in the derived class.\"\"\"</span>\n        <span class=\"token keyword\">raise</span> NotImplementedError\n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">save</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> sess<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token triple-quoted-string string\">\"\"\"Saves a snapshot of the model\n        Args:\n            sess (tf.Session): The current session.\n        \"\"\"</span>\n        <span class=\"token keyword\">if</span> self<span class=\"token punctuation\">.</span>saver <span class=\"token keyword\">is</span> <span class=\"token boolean\">None</span><span class=\"token punctuation\">:</span>\n            <span class=\"token keyword\">raise</span> SaverNotInitialized<span class=\"token punctuation\">(</span><span class=\"token punctuation\">(</span>\n                <span class=\"token string\">'saver not defined, please make sure '</span>\n                <span class=\"token string\">'self.saver = tf.train.Saver('</span>\n                <span class=\"token string\">'max_to_keep=config[\\'saver_max_to_keep\\']'</span>\n                <span class=\"token string\">') is in the constructor.'</span>\n            <span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'Saving model...'</span><span class=\"token punctuation\">)</span>\n        save_dir <span class=\"token operator\">=</span> os<span class=\"token punctuation\">.</span>path<span class=\"token punctuation\">.</span>join<span class=\"token punctuation\">(</span>\n            self<span class=\"token punctuation\">.</span>config<span class=\"token punctuation\">[</span><span class=\"token string\">'save_dir'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span>\n            self<span class=\"token punctuation\">.</span>name\n        <span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>saver<span class=\"token punctuation\">.</span>save<span class=\"token punctuation\">(</span>sess<span class=\"token punctuation\">,</span> save_dir <span class=\"token operator\">+</span> <span class=\"token string\">'/'</span> <span class=\"token operator\">+</span> self<span class=\"token punctuation\">.</span>name<span class=\"token punctuation\">,</span> self<span class=\"token punctuation\">.</span>global_step<span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'Save completed.\\n'</span><span class=\"token punctuation\">)</span>\n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">load</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> sess<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token triple-quoted-string string\">\"\"\"loads the last snapshot of the model\n        Args:\n            sess (tf.Session): The current session.\n        \"\"\"</span>\n        <span class=\"token keyword\">if</span> self<span class=\"token punctuation\">.</span>saver <span class=\"token keyword\">is</span> <span class=\"token boolean\">None</span><span class=\"token punctuation\">:</span>\n            <span class=\"token keyword\">raise</span> SaverNotInitialized<span class=\"token punctuation\">(</span><span class=\"token punctuation\">(</span>\n                <span class=\"token string\">'saver not defined, please make sure '</span>\n                <span class=\"token string\">'self.saver = tf.train.Saver('</span>\n                <span class=\"token string\">'max_to_keep=config[\\'saver_max_to_keep\\']'</span>\n                <span class=\"token string\">') is in the constructor.'</span>\n            <span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n        save_dir <span class=\"token operator\">=</span> os<span class=\"token punctuation\">.</span>path<span class=\"token punctuation\">.</span>join<span class=\"token punctuation\">(</span>\n            self<span class=\"token punctuation\">.</span>config<span class=\"token punctuation\">[</span><span class=\"token string\">'save_dir'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span>\n            self<span class=\"token punctuation\">.</span>name\n        <span class=\"token punctuation\">)</span>\n        latest_checkpoint <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>train<span class=\"token punctuation\">.</span>latest_checkpoint<span class=\"token punctuation\">(</span>save_dir<span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">if</span> latest_checkpoint<span class=\"token punctuation\">:</span>\n            <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>\n                <span class=\"token string\">'Loading model checkpoint {} ...\\n'</span><span class=\"token punctuation\">.</span><span class=\"token builtin\">format</span><span class=\"token punctuation\">(</span>latest_checkpoint<span class=\"token punctuation\">)</span>\n            <span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>saver<span class=\"token punctuation\">.</span>restore<span class=\"token punctuation\">(</span>sess<span class=\"token punctuation\">,</span> latest_checkpoint<span class=\"token punctuation\">)</span></code></pre></div>\n<p>This class functions the same way as the class seen in the template. That is, one will inherit from this class and implement the model_construtor function. The biggest difference here is that I decided to make use of the tf.data.Dataset API. In the constructor you will notice the following lines:</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\">self<span class=\"token punctuation\">.</span>x <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>placeholder<span class=\"token punctuation\">(</span>tf<span class=\"token punctuation\">.</span>float32<span class=\"token punctuation\">)</span>\nself<span class=\"token punctuation\">.</span>y <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>placeholder<span class=\"token punctuation\">(</span>tf<span class=\"token punctuation\">.</span>float32<span class=\"token punctuation\">)</span>\n\nself<span class=\"token punctuation\">.</span>data <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>data<span class=\"token punctuation\">.</span>Dataset<span class=\"token punctuation\">.</span>from_tensor_slices<span class=\"token punctuation\">(</span>\n    <span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span>x<span class=\"token punctuation\">,</span> self<span class=\"token punctuation\">.</span>y<span class=\"token punctuation\">)</span>\n<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>batch<span class=\"token punctuation\">(</span>\n    config<span class=\"token punctuation\">[</span><span class=\"token string\">'batch_size'</span><span class=\"token punctuation\">]</span>\n<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>repeat<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\nself<span class=\"token punctuation\">.</span>data_iter <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>data<span class=\"token punctuation\">.</span>make_initializable_iterator<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></code></pre></div>\n<p>Here I create a placeholder for the feature vectors (x) and labels (y) and create a dataset. From this dataset I then create an initializatle iterator. This will be very benefical because later I will be able to feed in different datasets without having to rewrite parts of my code. </p>\n<h3>Trainer</h3>\n<p>The trainer base class has the most changes compared to the other project. It still functions the same, where one defines the epoch function, but includes the methods train, test, and predict seen below:</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">def</span> <span class=\"token function\">train</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> features<span class=\"token punctuation\">,</span> labels<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token triple-quoted-string string\">\"\"\"Iterates over epochs preforming the training_step for each epoch.\n    \n    Args:\n        features (np.array): The feature vectors of the training set.\n        labels (np.array): The labels of the training set.\n    \"\"\"</span>\n    <span class=\"token keyword\">with</span> tf<span class=\"token punctuation\">.</span>name_scope<span class=\"token punctuation\">(</span><span class=\"token string\">'train'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        self<span class=\"token punctuation\">.</span>sess<span class=\"token punctuation\">.</span>run<span class=\"token punctuation\">(</span>\n            self<span class=\"token punctuation\">.</span>model<span class=\"token punctuation\">.</span>data_iter<span class=\"token punctuation\">.</span>initializer<span class=\"token punctuation\">,</span> \n            feed_dict<span class=\"token operator\">=</span><span class=\"token punctuation\">{</span>\n                self<span class=\"token punctuation\">.</span>model<span class=\"token punctuation\">.</span>x<span class=\"token punctuation\">:</span> features<span class=\"token punctuation\">,</span>\n                self<span class=\"token punctuation\">.</span>model<span class=\"token punctuation\">.</span>y<span class=\"token punctuation\">:</span> labels\n            <span class=\"token punctuation\">}</span>\n        <span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">for</span> epoch <span class=\"token keyword\">in</span> <span class=\"token builtin\">range</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span>model<span class=\"token punctuation\">.</span>config<span class=\"token punctuation\">[</span><span class=\"token string\">'num_epochs'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n            <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span>\n                <span class=\"token string\">'Epoch %d/%d'</span> <span class=\"token operator\">%</span> <span class=\"token punctuation\">(</span>epoch<span class=\"token operator\">+</span><span class=\"token number\">1</span><span class=\"token punctuation\">,</span> self<span class=\"token punctuation\">.</span>model<span class=\"token punctuation\">.</span>config<span class=\"token punctuation\">[</span><span class=\"token string\">'num_epochs'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n            <span class=\"token punctuation\">)</span>\n            self<span class=\"token punctuation\">.</span>epoch<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">def</span> <span class=\"token function\">test</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> features<span class=\"token punctuation\">,</span> labels<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token triple-quoted-string string\">\"\"\"Determines the loss and accuracy of the trained model on the \n    test set.\n    \n    Args:\n        features (np.array): The feature vectors of the test set.\n        labels (np.array): The labels of the test set.\n    \"\"\"</span>\n    self<span class=\"token punctuation\">.</span>sess<span class=\"token punctuation\">.</span>run<span class=\"token punctuation\">(</span>\n        self<span class=\"token punctuation\">.</span>model<span class=\"token punctuation\">.</span>data_iter<span class=\"token punctuation\">.</span>initializer<span class=\"token punctuation\">,</span> \n        feed_dict<span class=\"token operator\">=</span><span class=\"token punctuation\">{</span>\n            self<span class=\"token punctuation\">.</span>model<span class=\"token punctuation\">.</span>x<span class=\"token punctuation\">:</span> features<span class=\"token punctuation\">,</span>\n            self<span class=\"token punctuation\">.</span>model<span class=\"token punctuation\">.</span>y<span class=\"token punctuation\">:</span> labels\n        <span class=\"token punctuation\">}</span>\n    <span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">with</span> tf<span class=\"token punctuation\">.</span>name_scope<span class=\"token punctuation\">(</span><span class=\"token string\">'test'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        _<span class=\"token punctuation\">,</span> loss<span class=\"token punctuation\">,</span> accuracy <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>sess<span class=\"token punctuation\">.</span>run<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>\n                self<span class=\"token punctuation\">.</span>model<span class=\"token punctuation\">.</span>optimizer<span class=\"token punctuation\">,</span>\n                self<span class=\"token punctuation\">.</span>model<span class=\"token punctuation\">.</span>cross_entropy<span class=\"token punctuation\">,</span>\n                self<span class=\"token punctuation\">.</span>model<span class=\"token punctuation\">.</span>accuracy\n            <span class=\"token punctuation\">]</span>\n        <span class=\"token punctuation\">)</span>\n\n        <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'test cost: '</span><span class=\"token punctuation\">,</span> loss<span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'test accuracy: '</span><span class=\"token punctuation\">,</span> accuracy<span class=\"token punctuation\">)</span>\n        current_iteration <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>model<span class=\"token punctuation\">.</span>global_step<span class=\"token punctuation\">.</span><span class=\"token builtin\">eval</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span>sess<span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>logger<span class=\"token punctuation\">.</span>log<span class=\"token punctuation\">(</span>\n            <span class=\"token string\">'cost'</span><span class=\"token punctuation\">,</span>\n            loss<span class=\"token punctuation\">,</span>\n            current_iteration<span class=\"token punctuation\">,</span>\n            training<span class=\"token operator\">=</span><span class=\"token boolean\">False</span>\n        <span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>logger<span class=\"token punctuation\">.</span>log<span class=\"token punctuation\">(</span>\n            <span class=\"token string\">'accuracy'</span><span class=\"token punctuation\">,</span>\n            accuracy<span class=\"token punctuation\">,</span>\n            current_iteration<span class=\"token punctuation\">,</span>\n            training<span class=\"token operator\">=</span><span class=\"token boolean\">False</span>\n        <span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>model<span class=\"token punctuation\">.</span>save<span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span>sess<span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">def</span> <span class=\"token function\">predict</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> feature<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token triple-quoted-string string\">\"\"\"Abstract method to fetch a prediction.\n    Args:\n        feature (np.array): The feature vector to predict a label of.\n    \"\"\"</span>\n<span class=\"token keyword\">raise</span> NotImplementedError</code></pre></div>\n<p>In the training method, one passes the training features and labels. Here you can see the power of the dataset API. Here the initalizer method of the data iterator is called and fed the training data. In a similar fashion the dataset API is also used in the test method to feed in the test set. Finally, I added a predict method, which is ment to be implemented by the child class in order to fetch a prediction for a single feature vector. </p>\n<h3>Logger</h3>\n<p>The logger is fairly straightfoward. It contains only 2 methods log and add<em>graph. The log method will log a value that is passed. It has optional arguments such as is</em>image and trainig. If is_image is true it will store the value as an image and if training is false it will log to the test summary. The add graph method will save the graph to the summary. This is useful when one wants to also view the graph in tensorboard.</p>\n<h2>Example</h2>\n<p>Below is an example of how to use the core classes. The example below is just a simple MLP for the MNIST dataset.</p>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> tensorflow <span class=\"token keyword\">as</span> tf\n<span class=\"token keyword\">import</span> numpy <span class=\"token keyword\">as</span> np\n<span class=\"token keyword\">from</span> tqdm <span class=\"token keyword\">import</span> tqdm\n<span class=\"token keyword\">from</span> core<span class=\"token punctuation\">.</span>model <span class=\"token keyword\">import</span> Model\n<span class=\"token keyword\">from</span> core<span class=\"token punctuation\">.</span>trainer <span class=\"token keyword\">import</span> Trainer\n<span class=\"token keyword\">from</span> core<span class=\"token punctuation\">.</span>logger <span class=\"token keyword\">import</span> Logger\n\n\n<span class=\"token keyword\">class</span> <span class=\"token class-name\">TestModel</span><span class=\"token punctuation\">(</span>Model<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">def</span> <span class=\"token function\">__init__</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> config<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token builtin\">super</span><span class=\"token punctuation\">(</span>TestModel<span class=\"token punctuation\">,</span> self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>__init__<span class=\"token punctuation\">(</span>config<span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>model_constructor<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>saver <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>train<span class=\"token punctuation\">.</span>Saver<span class=\"token punctuation\">(</span>\n            max_to_keep<span class=\"token operator\">=</span>self<span class=\"token punctuation\">.</span>config<span class=\"token punctuation\">[</span><span class=\"token string\">'saver_max_to_keep'</span><span class=\"token punctuation\">]</span>\n        <span class=\"token punctuation\">)</span>\n    \n    <span class=\"token keyword\">def</span> <span class=\"token function\">model_constructor</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token triple-quoted-string string\">\"\"\"Constructs a simple MLP for the mnist dataset.\"\"\"</span>\n        n_layer_1 <span class=\"token operator\">=</span> <span class=\"token number\">256</span> <span class=\"token comment\"># 1st layer number of neurons</span>\n        n_layer_2 <span class=\"token operator\">=</span> <span class=\"token number\">256</span> <span class=\"token comment\"># 2nd layer number of neurons</span>\n        n_input <span class=\"token operator\">=</span> <span class=\"token number\">784</span> <span class=\"token comment\"># MNIST data input (img shape: 28*28)</span>\n        n_classes <span class=\"token operator\">=</span> <span class=\"token number\">10</span> <span class=\"token comment\"># MNIST total classes (0-9 digits)</span>\n\n        <span class=\"token keyword\">with</span> tf<span class=\"token punctuation\">.</span>name_scope<span class=\"token punctuation\">(</span><span class=\"token string\">'input'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n            self<span class=\"token punctuation\">.</span>features<span class=\"token punctuation\">,</span> self<span class=\"token punctuation\">.</span>labels <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>data_iter<span class=\"token punctuation\">.</span>get_next<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n        <span class=\"token keyword\">with</span> tf<span class=\"token punctuation\">.</span>name_scope<span class=\"token punctuation\">(</span><span class=\"token string\">'layer_1'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n            weights <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>Variable<span class=\"token punctuation\">(</span>\n                tf<span class=\"token punctuation\">.</span>random_normal<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>n_input<span class=\"token punctuation\">,</span> n_layer_1<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n                name<span class=\"token operator\">=</span><span class=\"token string\">'weights'</span>\n            <span class=\"token punctuation\">)</span>\n            bias <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>Variable<span class=\"token punctuation\">(</span>\n                tf<span class=\"token punctuation\">.</span>random_normal<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>n_layer_1<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n                name<span class=\"token operator\">=</span><span class=\"token string\">'bias'</span>\n            <span class=\"token punctuation\">)</span>\n            layer_1 <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>sigmoid<span class=\"token punctuation\">(</span>\n                tf<span class=\"token punctuation\">.</span>add<span class=\"token punctuation\">(</span>\n                    tf<span class=\"token punctuation\">.</span>matmul<span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span>features<span class=\"token punctuation\">,</span> weights<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n                    bias\n                <span class=\"token punctuation\">)</span>\n            <span class=\"token punctuation\">)</span>\n\n        <span class=\"token keyword\">with</span> tf<span class=\"token punctuation\">.</span>name_scope<span class=\"token punctuation\">(</span><span class=\"token string\">'layer_2'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n            weights <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>Variable<span class=\"token punctuation\">(</span>\n                tf<span class=\"token punctuation\">.</span>random_normal<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>n_layer_1<span class=\"token punctuation\">,</span> n_layer_2<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n                name<span class=\"token operator\">=</span><span class=\"token string\">'weights'</span>\n            <span class=\"token punctuation\">)</span>\n            bias <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>Variable<span class=\"token punctuation\">(</span>\n                tf<span class=\"token punctuation\">.</span>random_normal<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>n_layer_2<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n                name<span class=\"token operator\">=</span><span class=\"token string\">'bias'</span>\n            <span class=\"token punctuation\">)</span>\n            layer_2 <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>sigmoid<span class=\"token punctuation\">(</span>\n                tf<span class=\"token punctuation\">.</span>add<span class=\"token punctuation\">(</span>\n                    tf<span class=\"token punctuation\">.</span>matmul<span class=\"token punctuation\">(</span>layer_1<span class=\"token punctuation\">,</span> weights<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n                    bias\n                <span class=\"token punctuation\">)</span>\n            <span class=\"token punctuation\">)</span>\n\n        <span class=\"token keyword\">with</span> tf<span class=\"token punctuation\">.</span>name_scope<span class=\"token punctuation\">(</span><span class=\"token string\">'layer_3'</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n            weights <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>Variable<span class=\"token punctuation\">(</span>\n                tf<span class=\"token punctuation\">.</span>random_normal<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>n_layer_2<span class=\"token punctuation\">,</span> n_classes<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n                name<span class=\"token operator\">=</span><span class=\"token string\">'weights'</span>\n            <span class=\"token punctuation\">)</span>\n            bias <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>Variable<span class=\"token punctuation\">(</span>\n                tf<span class=\"token punctuation\">.</span>random_normal<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>n_classes<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n                name<span class=\"token operator\">=</span><span class=\"token string\">'bias'</span>\n            <span class=\"token punctuation\">)</span>\n            output <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>sigmoid<span class=\"token punctuation\">(</span>\n                tf<span class=\"token punctuation\">.</span>add<span class=\"token punctuation\">(</span>\n                    tf<span class=\"token punctuation\">.</span>matmul<span class=\"token punctuation\">(</span>layer_2<span class=\"token punctuation\">,</span> weights<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n                    bias\n                <span class=\"token punctuation\">)</span>\n            <span class=\"token punctuation\">)</span>\n\n        self<span class=\"token punctuation\">.</span>cross_entropy <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>reduce_mean<span class=\"token punctuation\">(</span>\n            tf<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>softmax_cross_entropy_with_logits_v2<span class=\"token punctuation\">(</span>\n                labels<span class=\"token operator\">=</span>self<span class=\"token punctuation\">.</span>labels<span class=\"token punctuation\">,</span>\n                logits<span class=\"token operator\">=</span>output\n            <span class=\"token punctuation\">)</span>\n        <span class=\"token punctuation\">)</span>\n\n        self<span class=\"token punctuation\">.</span>optimizer <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>train<span class=\"token punctuation\">.</span>AdamOptimizer<span class=\"token punctuation\">(</span>\n            self<span class=\"token punctuation\">.</span>config<span class=\"token punctuation\">[</span><span class=\"token string\">'learning_rate'</span><span class=\"token punctuation\">]</span>\n        <span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>minimize<span class=\"token punctuation\">(</span>\n            self<span class=\"token punctuation\">.</span>cross_entropy<span class=\"token punctuation\">,</span>\n            global_step<span class=\"token operator\">=</span>self<span class=\"token punctuation\">.</span>global_step\n        <span class=\"token punctuation\">)</span>\n\n        self<span class=\"token punctuation\">.</span>pred <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>nn<span class=\"token punctuation\">.</span>softmax<span class=\"token punctuation\">(</span>output<span class=\"token punctuation\">)</span>\n        correct_prediction <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>equal<span class=\"token punctuation\">(</span>\n            tf<span class=\"token punctuation\">.</span>argmax<span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span>pred<span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n            tf<span class=\"token punctuation\">.</span>argmax<span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span>labels<span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span>\n        <span class=\"token punctuation\">)</span>\n\n        self<span class=\"token punctuation\">.</span>accuracy <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>reduce_mean<span class=\"token punctuation\">(</span>\n            tf<span class=\"token punctuation\">.</span>cast<span class=\"token punctuation\">(</span>correct_prediction<span class=\"token punctuation\">,</span> tf<span class=\"token punctuation\">.</span>float32<span class=\"token punctuation\">)</span>\n        <span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">class</span> <span class=\"token class-name\">TestTrainer</span><span class=\"token punctuation\">(</span>Trainer<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">def</span> <span class=\"token function\">__init__</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> sess<span class=\"token punctuation\">,</span> model<span class=\"token punctuation\">,</span> logger<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token builtin\">super</span><span class=\"token punctuation\">(</span>TestTrainer<span class=\"token punctuation\">,</span> self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>__init__<span class=\"token punctuation\">(</span>sess<span class=\"token punctuation\">,</span> model<span class=\"token punctuation\">,</span> logger<span class=\"token punctuation\">)</span>\n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">epoch</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token triple-quoted-string string\">\"\"\"The logic for a single epoch of training. Loops though the batches \n        and logs the average loss and accuracy.\n        \"\"\"</span>\n        batch_loop <span class=\"token operator\">=</span> tqdm<span class=\"token punctuation\">(</span><span class=\"token builtin\">range</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span>model<span class=\"token punctuation\">.</span>config<span class=\"token punctuation\">[</span><span class=\"token string\">'iterations_per_epoch'</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n        losses <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span>\n        accuracies <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span>\n        <span class=\"token keyword\">for</span> _ <span class=\"token keyword\">in</span> batch_loop<span class=\"token punctuation\">:</span>\n            loss<span class=\"token punctuation\">,</span> accuracy <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>batch_step<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n            losses<span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span>loss<span class=\"token punctuation\">)</span>\n            accuracies<span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span>accuracy<span class=\"token punctuation\">)</span>\n\n        <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">''</span><span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'cost: %f'</span> <span class=\"token operator\">%</span> np<span class=\"token punctuation\">.</span>mean<span class=\"token punctuation\">(</span>losses<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'accuracy: %f \\n'</span> <span class=\"token operator\">%</span> np<span class=\"token punctuation\">.</span>mean<span class=\"token punctuation\">(</span>accuracies<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\n\n        current_iteration <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>model<span class=\"token punctuation\">.</span>global_step<span class=\"token punctuation\">.</span><span class=\"token builtin\">eval</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span>sess<span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>logger<span class=\"token punctuation\">.</span>log<span class=\"token punctuation\">(</span>\n            <span class=\"token string\">'cost'</span><span class=\"token punctuation\">,</span>\n            np<span class=\"token punctuation\">.</span>mean<span class=\"token punctuation\">(</span>losses<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n            current_iteration\n        <span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>logger<span class=\"token punctuation\">.</span>log<span class=\"token punctuation\">(</span>\n            <span class=\"token string\">'accuracy'</span><span class=\"token punctuation\">,</span>\n            np<span class=\"token punctuation\">.</span>mean<span class=\"token punctuation\">(</span>accuracies<span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n            current_iteration\n        <span class=\"token punctuation\">)</span>\n        self<span class=\"token punctuation\">.</span>model<span class=\"token punctuation\">.</span>save<span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span>sess<span class=\"token punctuation\">)</span>\n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">batch_step</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        <span class=\"token triple-quoted-string string\">\"\"\"Calculates the loss and accuracy per batch.\"\"\"</span>\n        _<span class=\"token punctuation\">,</span> loss<span class=\"token punctuation\">,</span> accuracy <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>sess<span class=\"token punctuation\">.</span>run<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>\n                self<span class=\"token punctuation\">.</span>model<span class=\"token punctuation\">.</span>optimizer<span class=\"token punctuation\">,</span>\n                self<span class=\"token punctuation\">.</span>model<span class=\"token punctuation\">.</span>cross_entropy<span class=\"token punctuation\">,</span>\n                self<span class=\"token punctuation\">.</span>model<span class=\"token punctuation\">.</span>accuracy\n            <span class=\"token punctuation\">]</span>\n        <span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">return</span> loss<span class=\"token punctuation\">,</span> accuracy\n\n    <span class=\"token keyword\">def</span> <span class=\"token function\">predict</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> feature<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n        prediction <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>sess<span class=\"token punctuation\">.</span>run<span class=\"token punctuation\">(</span>\n            self<span class=\"token punctuation\">.</span>model<span class=\"token punctuation\">.</span>pred<span class=\"token punctuation\">,</span>\n            feed_dict<span class=\"token operator\">=</span><span class=\"token punctuation\">{</span>\n                self<span class=\"token punctuation\">.</span>model<span class=\"token punctuation\">.</span>features<span class=\"token punctuation\">:</span> <span class=\"token punctuation\">[</span>feature<span class=\"token punctuation\">]</span>\n            <span class=\"token punctuation\">}</span>\n        <span class=\"token punctuation\">)</span>\n        <span class=\"token keyword\">return</span> np<span class=\"token punctuation\">.</span>argmax<span class=\"token punctuation\">(</span>prediction<span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">def</span> <span class=\"token function\">main</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token comment\"># Load mnist dataset</span>\n    train<span class=\"token punctuation\">,</span> test <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>datasets<span class=\"token punctuation\">.</span>mnist<span class=\"token punctuation\">.</span>load_data<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n    <span class=\"token comment\"># Build training set</span>\n    mnist_x<span class=\"token punctuation\">,</span> mnist_y <span class=\"token operator\">=</span> train\n    vec_mnist_y <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span>\n    <span class=\"token keyword\">for</span> y <span class=\"token keyword\">in</span> mnist_y<span class=\"token punctuation\">:</span>\n        vec <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>zeros<span class=\"token punctuation\">(</span><span class=\"token punctuation\">(</span><span class=\"token number\">10</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n        vec<span class=\"token punctuation\">[</span>y<span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> <span class=\"token number\">1.0</span>\n        vec_mnist_y<span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span>vec<span class=\"token punctuation\">)</span>\n    train_x <span class=\"token operator\">=</span> mnist_x<span class=\"token punctuation\">.</span>reshape<span class=\"token punctuation\">(</span><span class=\"token punctuation\">(</span><span class=\"token number\">60000</span><span class=\"token punctuation\">,</span> <span class=\"token number\">784</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>astype<span class=\"token punctuation\">(</span>np<span class=\"token punctuation\">.</span>float32<span class=\"token punctuation\">)</span>\n    train_y <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>array<span class=\"token punctuation\">(</span>vec_mnist_y<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>astype<span class=\"token punctuation\">(</span>np<span class=\"token punctuation\">.</span>float32<span class=\"token punctuation\">)</span>\n\n    <span class=\"token comment\"># Build test set</span>\n    mnist_x<span class=\"token punctuation\">,</span> mnist_y <span class=\"token operator\">=</span> test\n    vec_mnist_y <span class=\"token operator\">=</span> <span class=\"token punctuation\">[</span><span class=\"token punctuation\">]</span>\n    <span class=\"token keyword\">for</span> y <span class=\"token keyword\">in</span> mnist_y<span class=\"token punctuation\">:</span>\n        vec <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>zeros<span class=\"token punctuation\">(</span><span class=\"token punctuation\">(</span><span class=\"token number\">10</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n        vec<span class=\"token punctuation\">[</span>y<span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> <span class=\"token number\">1.0</span>\n        vec_mnist_y<span class=\"token punctuation\">.</span>append<span class=\"token punctuation\">(</span>vec<span class=\"token punctuation\">)</span>\n    test_x <span class=\"token operator\">=</span> mnist_x<span class=\"token punctuation\">.</span>reshape<span class=\"token punctuation\">(</span><span class=\"token punctuation\">(</span>mnist_x<span class=\"token punctuation\">.</span>shape<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> <span class=\"token number\">784</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>astype<span class=\"token punctuation\">(</span>np<span class=\"token punctuation\">.</span>float32<span class=\"token punctuation\">)</span>\n    test_y <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>array<span class=\"token punctuation\">(</span>vec_mnist_y<span class=\"token punctuation\">)</span><span class=\"token punctuation\">.</span>astype<span class=\"token punctuation\">(</span>np<span class=\"token punctuation\">.</span>float32<span class=\"token punctuation\">)</span>\n\n    config <span class=\"token operator\">=</span> <span class=\"token punctuation\">{</span>\n        <span class=\"token string\">'name'</span><span class=\"token punctuation\">:</span> <span class=\"token string\">'TestModel'</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">'batch_size'</span><span class=\"token punctuation\">:</span> <span class=\"token number\">100</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">'num_epochs'</span><span class=\"token punctuation\">:</span> <span class=\"token number\">5</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">'iterations_per_epoch'</span><span class=\"token punctuation\">:</span> <span class=\"token builtin\">int</span><span class=\"token punctuation\">(</span><span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>train_x<span class=\"token punctuation\">)</span><span class=\"token operator\">/</span><span class=\"token number\">100</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">'learning_rate'</span><span class=\"token punctuation\">:</span> <span class=\"token number\">0.001</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">'summary_dir'</span><span class=\"token punctuation\">:</span> <span class=\"token string\">'logs'</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">'save_dir'</span><span class=\"token punctuation\">:</span> <span class=\"token string\">'snapshots'</span><span class=\"token punctuation\">,</span>\n        <span class=\"token string\">'saver_max_to_keep'</span><span class=\"token punctuation\">:</span> <span class=\"token number\">5</span>\n    <span class=\"token punctuation\">}</span>\n\n    <span class=\"token comment\"># Instantiate the session, logger, model and trainer</span>\n    sess <span class=\"token operator\">=</span> tf<span class=\"token punctuation\">.</span>Session<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n    logger <span class=\"token operator\">=</span> Logger<span class=\"token punctuation\">(</span>sess<span class=\"token punctuation\">,</span> config<span class=\"token punctuation\">)</span>\n    model <span class=\"token operator\">=</span> TestModel<span class=\"token punctuation\">(</span>config<span class=\"token punctuation\">)</span>\n    trainer <span class=\"token operator\">=</span> TestTrainer<span class=\"token punctuation\">(</span>sess<span class=\"token punctuation\">,</span> model<span class=\"token punctuation\">,</span> logger<span class=\"token punctuation\">)</span>\n\n    <span class=\"token comment\"># Visualize the graph in Tensorboard</span>\n    logger<span class=\"token punctuation\">.</span>add_graph<span class=\"token punctuation\">(</span>sess<span class=\"token punctuation\">.</span>graph<span class=\"token punctuation\">)</span>\n\n    <span class=\"token comment\"># Load the model if pre-trained</span>\n    model<span class=\"token punctuation\">.</span>load<span class=\"token punctuation\">(</span>sess<span class=\"token punctuation\">)</span>\n\n    <span class=\"token comment\"># Train</span>\n    trainer<span class=\"token punctuation\">.</span>train<span class=\"token punctuation\">(</span>train_x<span class=\"token punctuation\">,</span> train_y<span class=\"token punctuation\">)</span>\n\n    <span class=\"token comment\"># Test</span>\n    trainer<span class=\"token punctuation\">.</span>test<span class=\"token punctuation\">(</span>test_x<span class=\"token punctuation\">,</span> test_y<span class=\"token punctuation\">)</span>\n    \n    <span class=\"token comment\"># Get a prediction for a single feature vector</span>\n    prediction <span class=\"token operator\">=</span> trainer<span class=\"token punctuation\">.</span>predict<span class=\"token punctuation\">(</span>test_x<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'prediction: '</span><span class=\"token punctuation\">,</span> prediction<span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">print</span><span class=\"token punctuation\">(</span><span class=\"token string\">'actual: '</span><span class=\"token punctuation\">,</span> np<span class=\"token punctuation\">.</span>argmax<span class=\"token punctuation\">(</span>test_y<span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">if</span> __name__ <span class=\"token operator\">==</span> <span class=\"token string\">'__main__'</span><span class=\"token punctuation\">:</span>\n    main<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></code></pre></div>","frontmatter":{"date":"June 22, 2017","path":"/tf-boilerplate","title":"Tensorflow boilerplate","image":{"childImageSharp":{"sizes":{"base64":"data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAALABQDASIAAhEBAxEB/8QAFwABAQEBAAAAAAAAAAAAAAAAAAIBBf/EABUBAQEAAAAAAAAAAAAAAAAAAAAB/9oADAMBAAIQAxAAAAHvxaNFf//EABgQAAIDAAAAAAAAAAAAAAAAAAABAhEg/9oACAEBAAEFAiLvP//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQMBAT8BP//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQIBAT8BP//EABYQAAMAAAAAAAAAAAAAAAAAAAAgMf/aAAgBAQAGPwIi/wD/xAAYEAEAAwEAAAAAAAAAAAAAAAARAAEgIf/aAAgBAQABPyGWpHTP/9oADAMBAAIAAwAAABC8D//EABYRAAMAAAAAAAAAAAAAAAAAABARIf/aAAgBAwEBPxBwf//EABYRAQEBAAAAAAAAAAAAAAAAAAEQEf/aAAgBAgEBPxBHZ//EABcQAQEBAQAAAAAAAAAAAAAAAAEREAD/2gAIAQEAAT8QWHJWEQrboBn/2Q==","aspectRatio":1.7777777777777777,"src":"/static/892679fe7d45d1f6a18e108eae95c41d/30037/tf.jpg","srcSet":"/static/892679fe7d45d1f6a18e108eae95c41d/10bdc/tf.jpg 158w,\n/static/892679fe7d45d1f6a18e108eae95c41d/f4ab0/tf.jpg 315w,\n/static/892679fe7d45d1f6a18e108eae95c41d/30037/tf.jpg 630w,\n/static/892679fe7d45d1f6a18e108eae95c41d/ca627/tf.jpg 688w","sizes":"(max-width: 630px) 100vw, 630px"}}}}}},"pageContext":{"isCreatedByStatefulCreatePages":false}}}